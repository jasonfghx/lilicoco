{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"name":"LSTM Model.ipynb","version":"0.3.2","provenance":[]},"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"}},"cells":[{"metadata":{"id":"NjZMS9oOSaig","colab_type":"text"},"cell_type":"markdown","source":["在這個模型中，我們將3個LSTM層疊在一起，使模型能夠學習更高層次的時間表示。\n","前兩個LSTM返回完整的輸出序列，但最後一個只返回輸出序列的最後一步，從而降低了時間維度（即將輸入序列轉換成單個向量）。\n"]},{"metadata":{"id":"UdrVXh1rSain","colab_type":"code","outputId":"0079bd18-0cf5-4a77-bcff-11dd550c2cec","colab":{}},"cell_type":"code","source":["from keras.models import Sequential\n","from keras.layers import LSTM, Dense\n","import numpy as np\n","\n","data_dim = 16\n","timesteps = 8\n","num_classes = 10\n","\n","# 期望输入数据尺寸: (batch_size, timesteps, data_dim)\n","model = Sequential()\n","model.add(LSTM(32, return_sequences=True,\n","               input_shape=(timesteps, data_dim)))  # 返回维度为 32 的向量序列\n","model.add(LSTM(32, return_sequences=True))  # 返回维度为 32 的向量序列\n","model.add(LSTM(32))  # 返回维度为 32 的单个向量\n","model.add(Dense(10, activation='softmax'))\n","\n","model.compile(loss='categorical_crossentropy',\n","              optimizer='rmsprop',\n","              metrics=['accuracy'])\n","\n","# 生成虚拟训练数据\n","x_train = np.random.random((1000, timesteps, data_dim))\n","y_train = np.random.random((1000, num_classes))\n","\n","# 生成虚拟验证数据\n","x_val = np.random.random((100, timesteps, data_dim))\n","y_val = np.random.random((100, num_classes))\n","\n","model.fit(x_train, y_train,\n","          batch_size=64, epochs=5,\n","          validation_data=(x_val, y_val))\n","\n"],"execution_count":0,"outputs":[{"output_type":"stream","text":["Using TensorFlow backend.\n"],"name":"stderr"},{"output_type":"stream","text":["Train on 1000 samples, validate on 100 samples\n","Epoch 1/5\n","1000/1000 [==============================] - 2s 2ms/step - loss: 11.5515 - acc: 0.0950 - val_loss: 11.5385 - val_acc: 0.0800\n","Epoch 2/5\n","1000/1000 [==============================] - 0s 172us/step - loss: 11.5500 - acc: 0.1130 - val_loss: 11.5353 - val_acc: 0.0700\n","Epoch 3/5\n","1000/1000 [==============================] - 0s 150us/step - loss: 11.5492 - acc: 0.1040 - val_loss: 11.5388 - val_acc: 0.0900\n","Epoch 4/5\n","1000/1000 [==============================] - 0s 168us/step - loss: 11.5493 - acc: 0.0840 - val_loss: 11.5347 - val_acc: 0.1200\n","Epoch 5/5\n","1000/1000 [==============================] - 0s 146us/step - loss: 11.5488 - acc: 0.1000 - val_loss: 11.5359 - val_acc: 0.1500\n"],"name":"stdout"},{"output_type":"execute_result","data":{"text/plain":["<keras.callbacks.History at 0x298826d4860>"]},"metadata":{"tags":[]},"execution_count":1}]},{"metadata":{"id":"zhDLcXKbSajM","colab_type":"text"},"cell_type":"markdown","source":["帶有狀態（stateful）的相同的棧式LSTM模型\n","有狀態的循環神經網絡模型中，在一個批次的樣本處理完成後，其內部狀態（記憶）會被記錄並作為下一個批次的樣本的初始狀態。這允許處理更長的序列，同時保持計算複雜度的可控性。\n"]},{"metadata":{"id":"ttqc-TJbSajQ","colab_type":"code","outputId":"7d58ad52-4707-4b44-fa09-5370e29fc0f8","colab":{}},"cell_type":"code","source":["from keras.models import Sequential\n","from keras.layers import LSTM, Dense\n","import numpy as np\n","\n","data_dim = 16\n","timesteps = 8\n","num_classes = 10\n","batch_size = 32\n","\n","# 期望输入数据尺寸: (batch_size, timesteps, data_dim)\n","# 请注意，我们必须提供完整的 batch_input_shape，因为网络是有状态的。\n","# 第 k 批数据的第 i 个样本是第 k-1 批数据的第 i 个样本的后续。\n","model = Sequential()\n","model.add(LSTM(32, return_sequences=True, stateful=True,\n","               batch_input_shape=(batch_size, timesteps, data_dim)))\n","model.add(LSTM(32, return_sequences=True, stateful=True))\n","model.add(LSTM(32, stateful=True))\n","model.add(Dense(10, activation='softmax'))\n","\n","model.compile(loss='categorical_crossentropy',\n","              optimizer='rmsprop',\n","              metrics=['accuracy'])\n","\n","# 生成虚拟训练数据\n","x_train = np.random.random((batch_size * 10, timesteps, data_dim))\n","y_train = np.random.random((batch_size * 10, num_classes))\n","\n","# 生成虚拟验证数据\n","x_val = np.random.random((batch_size * 3, timesteps, data_dim))\n","y_val = np.random.random((batch_size * 3, num_classes))\n","\n","model.fit(x_train, y_train,\n","          batch_size=batch_size, epochs=5, shuffle=False,\n","          validation_data=(x_val, y_val))"],"execution_count":0,"outputs":[{"output_type":"stream","text":["Train on 320 samples, validate on 96 samples\n","Epoch 1/5\n","320/320 [==============================] - 2s 6ms/step - loss: 11.5547 - acc: 0.0656 - val_loss: 11.4900 - val_acc: 0.0833\n","Epoch 2/5\n","320/320 [==============================] - 0s 229us/step - loss: 11.5497 - acc: 0.0719 - val_loss: 11.4905 - val_acc: 0.0625\n","Epoch 3/5\n","320/320 [==============================] - 0s 207us/step - loss: 11.5488 - acc: 0.1031 - val_loss: 11.4907 - val_acc: 0.0521\n","Epoch 4/5\n","320/320 [==============================] - 0s 195us/step - loss: 11.5480 - acc: 0.1031 - val_loss: 11.4909 - val_acc: 0.0521\n","Epoch 5/5\n","320/320 [==============================] - 0s 189us/step - loss: 11.5472 - acc: 0.1125 - val_loss: 11.4911 - val_acc: 0.0625\n"],"name":"stdout"},{"output_type":"execute_result","data":{"text/plain":["<keras.callbacks.History at 0x2988a54cb00>"]},"metadata":{"tags":[]},"execution_count":2}]},{"metadata":{"id":"y2td-0a7Sajh","colab_type":"code","colab":{}},"cell_type":"code","source":[""],"execution_count":0,"outputs":[]}]}